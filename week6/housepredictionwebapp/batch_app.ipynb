{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://128.134.65.180:5000/ (Press CTRL+C to quit)\n",
      "128.134.65.180 - - [25/Sep/2021 14:30:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "128.134.65.180 - - [25/Sep/2021 14:31:08] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
      "128.134.65.180 - - [25/Sep/2021 14:31:35] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # for manipulation\n",
    "import pandas as pd  # for data loading\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # for scaling the attributes\n",
    "from sklearn.preprocessing import OneHotEncoder  # for handling categorical features\n",
    "from sklearn.impute import SimpleImputer   # for handling missing data\n",
    "\n",
    "import pickle  # for importing model\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template  # for handling web service\n",
    "\n",
    "# Flask instantiation\n",
    "app = Flask(__name__, template_folder='templates')\n",
    "\n",
    "# Custom class for combined attributes\n",
    "class CombinedAttributesAdder():    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, rooms_ix, bedrooms_ix, population_ix, households_ix):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "        \n",
    "        X = np.delete(X, [households_ix, rooms_ix, population_ix, bedrooms_ix], 1)\n",
    "        \n",
    "        return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "\n",
    "# class for data preprocessing\n",
    "class data_preprocessing():\n",
    "    def __init__(self, imputer, scaler, ohencoder):\n",
    "        self.imputer = imputer\n",
    "        self.attr_add = CombinedAttributesAdder()\n",
    "        self.stdscale = scaler\n",
    "        self.ohe = ohencoder\n",
    "        \n",
    "    def fit(self, X, rooms_ix, bedrooms_ix, population_ix, households_ix): \n",
    "        # fit and transform the training data\n",
    "        house_num = X.drop(\"ocean_proximity\", axis=1)\n",
    "        house_cat = X[[\"ocean_proximity\"]]\n",
    "        \n",
    "        # handle missing data\n",
    "        self.imputer.fit(house_num)\n",
    "        X_train_imp = self.imputer.transform(house_num)\n",
    "        X_train_imp = pd.DataFrame(X_train_imp, columns=house_num.columns, index=X.index)\n",
    "        \n",
    "        # combined attributes\n",
    "        housing_addtl_attr = self.attr_add.transform(X_train_imp.values, rooms_ix, \n",
    "                                                     bedrooms_ix, population_ix, households_ix)\n",
    "        \n",
    "        # scale the features\n",
    "        self.stdscale.fit(housing_addtl_attr)\n",
    "        X_train_imp_scaled = self.stdscale.transform(housing_addtl_attr)\n",
    "        \n",
    "        # handle categorical input feature\n",
    "        self.ohe.fit(house_cat)\n",
    "        X_train_ohe = self.ohe.transform(house_cat)\n",
    "        \n",
    "        # concatenate features\n",
    "        X_train = np.concatenate([X_train_imp_scaled, X_train_ohe], axis=1)\n",
    "        \n",
    "        return X_train\n",
    "        \n",
    "    def transform(self, X, rooms_ix, bedrooms_ix, population_ix, households_ix): \n",
    "        # transform the test data (use the fitted imputer, \n",
    "        #                         standardscaler, onehotencoder, \n",
    "        #                         combinedattribute from training)\n",
    "        house_num = X.drop(\"ocean_proximity\", axis=1)\n",
    "        house_cat = X[[\"ocean_proximity\"]]\n",
    "        \n",
    "        # handle missing data\n",
    "        X_test_imp = self.imputer.transform(house_num)\n",
    "        X_test_imp = pd.DataFrame(X_test_imp, columns=house_num.columns, index=X.index)\n",
    "        \n",
    "        # combined attributes\n",
    "        housing_addtl_attr = self.attr_add.transform(X_test_imp.values, rooms_ix, \n",
    "                                                     bedrooms_ix, population_ix, households_ix)\n",
    "        \n",
    "        # scale the features\n",
    "        X_test_imp_scaled = self.stdscale.transform(housing_addtl_attr)\n",
    "        \n",
    "        # handle categorical input feature\n",
    "        X_test_ohe = self.ohe.transform(house_cat)\n",
    "        \n",
    "        # concatenate features\n",
    "        X_test = np.concatenate([X_test_imp_scaled, X_test_ohe], axis=1)\n",
    "        \n",
    "        return X_test\n",
    "    \n",
    "    def savefittedobject(self):\n",
    "        pickle.dump(self.imputer, open('houseimputer_retrain.pkl', 'wb'))\n",
    "        pickle.dump(self.stdscale, open('housescaler_retrain.pkl', 'wb'))\n",
    "        pickle.dump(self.ohe, open('houseohencoder_retrain.pkl', 'wb'))\n",
    "        \n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    # model and fitted object loading\n",
    "    model = pickle.load(open('houseregressionmodel.pkl', 'rb'))\n",
    "    imputer = pickle.load(open('houseimputer.pkl', 'rb'))\n",
    "    scaler = pickle.load(open('housescaler.pkl', 'rb'))\n",
    "    ohencoder = pickle.load(open('houseohencoder.pkl', 'rb'))\n",
    "    \n",
    "    # load the dataset\n",
    "    housing_data = pd.read_csv('housing_data.csv')\n",
    "    \n",
    "    if request.method == 'GET':\n",
    "        return(render_template('index.html'))\n",
    "    if request.method == 'POST':\n",
    "        # get input values\n",
    "        longitude = float(request.form['longitude'])\n",
    "        latitude = float(request.form['latitude'])\n",
    "        housingmedianage = float(request.form['housingmedianage'])\n",
    "        totalrooms = float(request.form['totalrooms'])\n",
    "        totalbedrooms = request.form['totalbedrooms']        \n",
    "        population = float(request.form['population'])\n",
    "        households = float(request.form['households'])\n",
    "        medianincome = float(request.form['medianincome'])\n",
    "        oceanproximity = request.form['oceanproximity']\n",
    "        \n",
    "        # handle missing input in total_bedrooms attribute\n",
    "        if totalbedrooms == '':\n",
    "            totalbedrooms = float('nan')\n",
    "        else:\n",
    "            totalbedrooms = float(totalbedrooms)\n",
    "        \n",
    "        # new category creation by assuming median income is a very important attribute \n",
    "        income_cat = pd.cut([medianincome],\n",
    "                              bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                              labels=[1, 2, 3, 4, 5])\n",
    "        \n",
    "        # convert input data to dataframe\n",
    "        inputs_ = {'longitude': longitude,\n",
    "                  'latitude': latitude,\n",
    "                  'housing_median_age': housingmedianage,\n",
    "                  'total_rooms': totalrooms,\n",
    "                  'total_bedrooms': totalbedrooms,\n",
    "                  'population': population,\n",
    "                  'households': households,\n",
    "                  'median_income': medianincome,\n",
    "                  'ocean_proximity': oceanproximity,\n",
    "                  'income_cat': income_cat}\n",
    "        \n",
    "        inputs_df = pd.DataFrame(inputs_)\n",
    "        \n",
    "        # get the column indices to be used in getting additional attributes\n",
    "        col_names = [\"total_rooms\", \"total_bedrooms\", \"population\", \"households\"]\n",
    "        rooms_ix, bedrooms_ix, population_ix, households_ix = [\n",
    "            inputs_df.columns.get_loc(c) for c in col_names] # get the column indices\n",
    "        \n",
    "        # preprocess the inputs\n",
    "        preprocessing_ = data_preprocessing(imputer, scaler, ohencoder)\n",
    "        inputs_preprocessed = preprocessing_.transform(inputs_df, rooms_ix, bedrooms_ix, \n",
    "                                                       population_ix, households_ix)\n",
    "        \n",
    "        # predict the price\n",
    "        prediction = model.predict(inputs_preprocessed)\n",
    "        \n",
    "        # batch training\n",
    "        # adding the median_house_value in the data for retraining\n",
    "        inputs_df['median_house_value'] = int(prediction[0])\n",
    "        # dropping the income_cat attribute before saving\n",
    "        inputs_df = inputs_df.drop(\"income_cat\", axis=1)\n",
    "        # saving to csv the new data\n",
    "        inputs_df.to_csv('housing_data.csv', mode='a', index=False, header=False)\n",
    "        # retraining\n",
    "        if len(housing_data) > 40:\n",
    "            # new category creation by assuming median income is a very important attribute \n",
    "            housing_data[\"income_cat\"] = pd.cut(housing_data[\"median_income\"],\n",
    "                                          bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                                          labels=[1, 2, 3, 4, 5])\n",
    "            \n",
    "            # assign the training data\n",
    "            train_housing = housing_data.drop(\"median_house_value\", axis=1)\n",
    "            train_housing_labels = housing_data[\"median_house_value\"].copy()\n",
    "            \n",
    "            # preprocess the training data\n",
    "            data_X_train = preprocessing_.fit(train_housing,rooms_ix, bedrooms_ix, \n",
    "                                                       population_ix, households_ix)\n",
    "            \n",
    "            # retrain the model\n",
    "            model.fit(data_X_train, train_housing_labels)\n",
    "            \n",
    "            # save the model\n",
    "            pickle.dump(model, open('houseregressionmodel_retrain.pkl', 'wb'))\n",
    "            \n",
    "            # save the fitted objects\n",
    "            preprocessing_.savefittedobject()\n",
    "    \n",
    "        return render_template('index.html', result=prediction[0])  \n",
    "    \n",
    "# running the application for serving\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"128.134.65.180\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
