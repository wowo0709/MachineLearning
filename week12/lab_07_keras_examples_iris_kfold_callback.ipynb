{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzbpqKRk7uzT"
   },
   "source": [
    "## Callback - check point and early stopping\n",
    "\n",
    "- Callback 함수: 명시적으로 호출되는 게 아니라 나중에 어떤 event 가 발생했을 때 호출되는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gafjD4O27uzU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHNY7zxnk0YG"
   },
   "source": [
    "- download wine.csv from https://codedragon.tistory.com/9480\n",
    "  - class 1: red wine, 0: white wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1631093793073,
     "user": {
      "displayName": "Yongjin Jeong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03658406798560557048"
     },
     "user_tz": -540
    },
    "id": "bj5eEiks7uzY",
    "outputId": "ae775bf3-0a9f-41d0-ed7f-bed7bfa0026d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('wine.csv', header=None)\n",
    "df = df_all.sample(frac=0.2)  # get only 20% of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1631093796459,
     "user": {
      "displayName": "Yongjin Jeong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03658406798560557048"
     },
     "user_tz": -540
    },
    "id": "TY5sKbdJnQBQ",
    "outputId": "d35f8816-7bf2-40f2-c8d9-3b0f077c4f94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.149</td>\n",
       "      <td>70.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.99304</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2    3      4     5   ...       7     8     9    10  11  12\n",
       "5510  7.2  0.23  0.82  1.3  0.149  70.0  ...  0.99304  2.93  0.42  9.2   6   0\n",
       "\n",
       "[1 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1631093799750,
     "user": {
      "displayName": "Yongjin Jeong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03658406798560557048"
     },
     "user_tz": -540
    },
    "id": "dV8EsphhnWsH",
    "outputId": "3d964f20-b295-45fd-be7d-6c32879a201c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    980\n",
       "1    319\n",
       "Name: 12, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[12].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yd7tFmGT7uzd"
   },
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "X, y = dataset[:,0:12], dataset[:,12]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# 모델 업데이트 및 저장 (epoch 마다)\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, \n",
    "                               monitor='val_loss', \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)  # record only when imrpoved\n",
    "\n",
    "# 테스트 오차가 줄지 않으면 학습 자동 중단 설정 (모니터할 값 저장)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', \n",
    "                                        patience=100) # 좋아지지 않아도 몇 번까지 기다릴것인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 25437,
     "status": "ok",
     "timestamp": 1631093908611,
     "user": {
      "displayName": "Yongjin Jeong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03658406798560557048"
     },
     "user_tz": -540
    },
    "id": "--_bUDPb7uzp",
    "outputId": "ae3891f9-de81-486f-bccd-ad8d57cc09f7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52311, saving model to ./model/01-0.5231.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52311 to 0.43001, saving model to ./model/02-0.4300.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43001 to 0.40039, saving model to ./model/03-0.4004.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40039 to 0.34686, saving model to ./model/04-0.3469.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34686 to 0.32681, saving model to ./model/05-0.3268.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32681 to 0.31282, saving model to ./model/06-0.3128.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31282 to 0.29247, saving model to ./model/07-0.2925.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.29247 to 0.28233, saving model to ./model/08-0.2823.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.28233 to 0.26633, saving model to ./model/09-0.2663.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.26633 to 0.25635, saving model to ./model/10-0.2563.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.25635 to 0.24855, saving model to ./model/11-0.2486.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.24855 to 0.24337, saving model to ./model/12-0.2434.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.24337 to 0.24000, saving model to ./model/13-0.2400.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.24000 to 0.23551, saving model to ./model/14-0.2355.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.23551 to 0.22977, saving model to ./model/15-0.2298.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.22977\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22977 to 0.22364, saving model to ./model/17-0.2236.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.22364\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22364 to 0.21843, saving model to ./model/19-0.2184.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21843 to 0.21092, saving model to ./model/20-0.2109.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.21092\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21092 to 0.20644, saving model to ./model/22-0.2064.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20644 to 0.20616, saving model to ./model/23-0.2062.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20616 to 0.20488, saving model to ./model/24-0.2049.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20488 to 0.20436, saving model to ./model/25-0.2044.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20436 to 0.20055, saving model to ./model/26-0.2006.hdf5\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20055\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20055 to 0.19664, saving model to ./model/28-0.1966.hdf5\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.19664\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19664 to 0.19348, saving model to ./model/30-0.1935.hdf5\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.19348\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19348 to 0.19254, saving model to ./model/32-0.1925.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19254 to 0.19115, saving model to ./model/33-0.1912.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19115 to 0.18714, saving model to ./model/34-0.1871.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.18714\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.18714\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18714 to 0.18361, saving model to ./model/37-0.1836.hdf5\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.18361 to 0.18176, saving model to ./model/38-0.1818.hdf5\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.18176\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18176 to 0.17799, saving model to ./model/40-0.1780.hdf5\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.17799\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.17799\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17799 to 0.17454, saving model to ./model/43-0.1745.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.17454\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.17454\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.17454\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.17454 to 0.17237, saving model to ./model/47-0.1724.hdf5\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.17237 to 0.17030, saving model to ./model/48-0.1703.hdf5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.17030\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.17030 to 0.16503, saving model to ./model/50-0.1650.hdf5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.16503\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.16503\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.16503 to 0.16363, saving model to ./model/53-0.1636.hdf5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.16363\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.16363 to 0.15809, saving model to ./model/55-0.1581.hdf5\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.15809\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.15809 to 0.15758, saving model to ./model/57-0.1576.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.15758\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.15758 to 0.15593, saving model to ./model/59-0.1559.hdf5\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.15593\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.15593 to 0.15388, saving model to ./model/61-0.1539.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.15388 to 0.15291, saving model to ./model/62-0.1529.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.15291 to 0.15153, saving model to ./model/63-0.1515.hdf5\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.15153\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.15153 to 0.14995, saving model to ./model/65-0.1500.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.14995 to 0.14530, saving model to ./model/66-0.1453.hdf5\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.14530\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.14530 to 0.14283, saving model to ./model/68-0.1428.hdf5\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.14283 to 0.14211, saving model to ./model/69-0.1421.hdf5\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.14211\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.14211 to 0.13523, saving model to ./model/71-0.1352.hdf5\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.13523\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.13523\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.13523\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.13523\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.13523\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.13523\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.13523\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.13523 to 0.12911, saving model to ./model/79-0.1291.hdf5\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.12911 to 0.12872, saving model to ./model/80-0.1287.hdf5\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.12872\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.12872\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.12872\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.12872\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.12872 to 0.12351, saving model to ./model/85-0.1235.hdf5\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.12351\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.12351\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.12351 to 0.11917, saving model to ./model/88-0.1192.hdf5\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.11917\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.11917\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.11917\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.11917\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.11917\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.11917\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.11917 to 0.10868, saving model to ./model/95-0.1087.hdf5\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10868\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10868\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10868\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10868\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10868\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.10868\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.10868\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.10868\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.10868 to 0.10550, saving model to ./model/104-0.1055.hdf5\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.10550\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.10550 to 0.10352, saving model to ./model/106-0.1035.hdf5\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.10352\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.10352\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.10352\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.10352\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.10352\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.10352\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.10352\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.10352 to 0.10261, saving model to ./model/114-0.1026.hdf5\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.10261\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.10261\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.10261\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.10261 to 0.09817, saving model to ./model/118-0.0982.hdf5\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.09817\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.09817\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.09817\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.09817 to 0.09649, saving model to ./model/122-0.0965.hdf5\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.09649 to 0.09562, saving model to ./model/123-0.0956.hdf5\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.09562\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.09562\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.09562\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.09562 to 0.09214, saving model to ./model/127-0.0921.hdf5\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.09214\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.09214 to 0.08924, saving model to ./model/141-0.0892.hdf5\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.08924\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.08924 to 0.08819, saving model to ./model/143-0.0882.hdf5\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.08819\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.08819 to 0.08677, saving model to ./model/154-0.0868.hdf5\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.08677 to 0.08616, saving model to ./model/155-0.0862.hdf5\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.08616\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.08616 to 0.08546, saving model to ./model/174-0.0855.hdf5\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.08546\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.08546 to 0.08424, saving model to ./model/203-0.0842.hdf5\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.08424\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.08424\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.08424\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.08424\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.08424\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.08424 to 0.08390, saving model to ./model/209-0.0839.hdf5\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.08390\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.08390 to 0.08296, saving model to ./model/226-0.0830.hdf5\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.08296\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.08296 to 0.08230, saving model to ./model/295-0.0823.hdf5\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.08230\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.08230\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_loss, y_acc, y_vloss, y_vacc = [], [], [], []\n",
    "\n",
    "history = model.fit(X, y, validation_split=0.2, \n",
    "                    epochs=2000, batch_size=100, verbose=0, \n",
    "                    callbacks=[early_stopping_callback,checkpointer])\n",
    "y_loss = history.history['loss']\n",
    "y_acc = history.history['accuracy']\n",
    "y_vloss = history.history['val_loss']\n",
    "y_vacc = history.history['val_accuracy']\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.ylim(0.,1.)\n",
    "plt.title(\"Traing\")\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"r\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"b\", markersize=3)\n",
    "plt.show()\n",
    "plt.title(\"Validation\")\n",
    "plt.ylim(0.,1.)\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"r\", markersize=3)\n",
    "plt.plot(x_len, y_vacc, \"o\", c=\"b\", markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1631093921160,
     "user": {
      "displayName": "Yongjin Jeong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03658406798560557048"
     },
     "user_tz": -540
    },
    "id": "vZkNuqKw_CzP",
    "outputId": "5505f55c-a8a2-4f4a-c032-78da331f482c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1631093921801,
     "user": {
      "displayName": "Yongjin Jeong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03658406798560557048"
     },
     "user_tz": -540
    },
    "id": "39jtzRIR7uzy",
    "outputId": "9235416d-688a-48f8-a577-7a86e1b5a324",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9823\n",
      "Acuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "print(\"Acuracy: %.4f\" %(model.evaluate(X, y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meV-aZzQ7uz3"
   },
   "source": [
    "- 2000 epoch 전에 중간에 중단됨을 알 수 있다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab_07_keras_examples_iris_kfold_callback.ipynb",
   "provenance": [
    {
     "file_id": "177bujbHqRnYCTG74IFQQQ-rcD7X_ozXc",
     "timestamp": 1605778327811
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
